{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modell Trainer\n",
    "Dieses Notebook kann verwendet werden, um das Modell zu Trainieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install ultralytics\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install scipy\n",
    "%pip install glob2\n",
    "%pip install Pillow\n",
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import Layout\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the image file\n",
    "\n",
    "label_mapping_file = (\n",
    "    r\"datasets\\UNIMIB2016\\orig\\labels_segmentation\\labelmap._darknet.labels\"\n",
    ")\n",
    "with open(label_mapping_file, \"r\") as file:\n",
    "    label_mapping = {i: line.rstrip() for i, line in enumerate(file)}\n",
    "\n",
    "\n",
    "def get_plot(name):\n",
    "    img_file = rf\"datasets\\UNIMIB2016\\orig\\images\\{name}.jpg\"\n",
    "    label_file = rf\"datasets\\UNIMIB2016\\orig\\labels_segmentation\\{name}.txt\"\n",
    "    img = Image.open(img_file)\n",
    "    width, height = img.size\n",
    "    fig, ax = plt.subplots(1)\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(img)\n",
    "\n",
    "    def parse_line(line):\n",
    "        # Split the line into label id and coordinates\n",
    "        segments = line.strip().split()\n",
    "        label_id = int(segments[0])\n",
    "        coordinates = list(map(float, segments[1:]))\n",
    "\n",
    "        # Group the coordinates into pairs (x, y)\n",
    "        vertices = list(zip(coordinates[::2], coordinates[1::2]))\n",
    "        return label_id, vertices\n",
    "\n",
    "    # Open the label file\n",
    "    with open(label_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # For each line in the file, draw the polygon\n",
    "    for i, line in enumerate(lines):\n",
    "        # Parse the line to get the class id and the polygon points\n",
    "        class_id, polygon_points = parse_line(\n",
    "            line\n",
    "        )  # You'll need to implement this function\n",
    "        polygon_points = [(x * width, y * height) for x, y in polygon_points]\n",
    "        # Create a Polygon patch\n",
    "        poly = patches.Polygon(\n",
    "            polygon_points, fill=True, alpha=0.5, color=cm.tab10(i % 10)\n",
    "        )\n",
    "\n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(poly)\n",
    "\n",
    "        # Add the label\n",
    "        centroid = np.mean(polygon_points, axis=0)\n",
    "        plt.text(centroid[0], centroid[1], label_mapping[class_id], color=\"black\")\n",
    "\n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(poly)\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of image and label files\n",
    "image_dir = \"datasets/UNIMIB2016/orig/images/\"\n",
    "label_dir = \"datasets/UNIMIB2016/orig/labels_segmentation/\"\n",
    "image_files = sorted(os.listdir(image_dir))\n",
    "label_files = sorted(os.listdir(label_dir))\n",
    "\n",
    "\n",
    "# Create widgets\n",
    "output = widgets.Output()\n",
    "# Create widgets\n",
    "output = widgets.Output()\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=image_files, value=image_files[0], description=\"Bild\"\n",
    ")\n",
    "text = widgets.Text(value=image_files[0], description=\"Bildtext\")\n",
    "\n",
    "\n",
    "def update_widget(change):\n",
    "    # Update slider value\n",
    "    update_image(change.new)\n",
    "\n",
    "\n",
    "def update_image(name):\n",
    "    dropdown.value = name\n",
    "    text.value = name\n",
    "    # Update image\n",
    "    output.clear_output()\n",
    "\n",
    "    # Get the name of the image file without extension\n",
    "    name = name.split(\".\")[0]\n",
    "\n",
    "    # Display the image with polygons\n",
    "    with output:\n",
    "        get_plot(name).show()\n",
    "\n",
    "\n",
    "dropdown.observe(update_widget, names=\"value\")\n",
    "text.observe(update_widget, names=\"value\")\n",
    "update_image(text.value)\n",
    "\n",
    "# Display widgets20151130_114034 20151130_122541\n",
    "display(widgets.HBox([dropdown, text]), output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(dir, files):\n",
    "    def parse_line(line):\n",
    "        segments = line.strip().split()\n",
    "        label_id = int(segments[0])\n",
    "        return label_mapping[label_id]\n",
    "\n",
    "    output = {}\n",
    "    for file in files[:-1]:\n",
    "        with open(dir + file) as f:\n",
    "            lines = f.readlines()\n",
    "            classes = [parse_line(line) for line in lines]\n",
    "        output[file] = classes\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterForToLittleOccurences():\n",
    "    def __init__(self):\n",
    "        self.df = self.get_df_with_labels_in_header()\n",
    "        self.categories = self.get_food_that_have_less_than_4_occurences(self.df)\n",
    "        self.files_to_filter_out = (\n",
    "            self.get_files_with_food_that_have_too_little_occurences(\n",
    "                self.df, self.categories\n",
    "            )\n",
    "        )\n",
    "        # self.move_files(self.files_to_filter_out)\n",
    "\n",
    "    def get_df_with_labels_in_header(self):\n",
    "        labels = get_labels(label_dir, label_files)\n",
    "\n",
    "        data = {\n",
    "            \"name\": list(labels.keys()),\n",
    "            **{\n",
    "                key: [True if key in value else False for value in labels.values()]\n",
    "                for key in set(\n",
    "                    [item for sublist in labels.values() for item in sublist]\n",
    "                )\n",
    "\n",
    "            },\n",
    "        }\n",
    "\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "    def get_food_that_have_less_than_4_occurences(self, df):\n",
    "        counts = df.iloc[:, 1:].apply(lambda x: x.sum(), axis=0)\n",
    "\n",
    "        foods_with_less_than_4 = counts.where(counts < 4).dropna()\n",
    "\n",
    "        return foods_with_less_than_4.index.to_list()\n",
    "\n",
    "\n",
    "    def get_files_with_food_that_have_too_little_occurences(self, df, categories):\n",
    "\n",
    "        return df[df[categories].any(axis=1)].name.to_list()\n",
    "\n",
    "\n",
    "    def move_files(self, files):\n",
    "        images_dir = r\"datasets\\UNIMIB2016\\orig\\images\"\n",
    "\n",
    "        labels_dir = r\"datasets\\UNIMIB2016\\orig\\labels_segmentation\"\n",
    "\n",
    "\n",
    "        # Create the train, test, val directories if they don't exist\n",
    "\n",
    "\n",
    "        os.makedirs(\"datasets/UNIMIB2016/sorted_out/images\", exist_ok=True)\n",
    "\n",
    "        os.makedirs(\"datasets/UNIMIB2016/sorted_out/labels\", exist_ok=True)\n",
    "\n",
    "        for file in files:\n",
    "            shutil.move(\n",
    "                os.path.join(images_dir, Path(file).stem + \".jpg\"),\n",
    "                \"datasets/UNIMIB2016/sorted_out/images\",\n",
    "            )\n",
    "\n",
    "\n",
    "            shutil.move(\n",
    "                os.path.join(labels_dir, Path(file)),\n",
    "                \"datasets/UNIMIB2016/sorted_out/labels\",\n",
    "\n",
    "            )\n",
    "\n",
    "\n",
    "FilterForToLittleOccurences().categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_labels(label_dir, label_files)\n",
    "df = pd.DataFrame(\n",
    "    {\"name\": labels.keys(), \"meals\": [\", \".join(labels) for labels in labels.values()]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## look at labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_labels={food for label in labels.values() for food in label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels={\"patate/pure\",\n",
    "\"pasta_mare_e_monti\",\n",
    "\"pizza\",\n",
    "\"budino\",\n",
    "\"mandarini\",\n",
    "\"pasta_zafferano_e_piselli\",\n",
    "\"arrosto\",\n",
    "\"yogurt\",\n",
    "\"pane\",\n",
    "\"torta_salata_spinaci_e_ricotta\",\n",
    "\"rosbeef\",\n",
    "\"pizzoccheri\",\n",
    "\"arancia\",\n",
    "\"carote\",\n",
    "\"fagiolini\",\n",
    "\"pesce_(filetto)\",\n",
    "\"spinaci\",\n",
    "\"torta_cioccolato_e_pere\",\n",
    "\"cotoletta\",\n",
    "\"patatine_fritte\",\n",
    "\"scaloppine\",\n",
    "\"insalata_2_(uova mais)\",\n",
    "\"insalata_mista\",\n",
    "\"pasta_sugo\",\n",
    "\"riso_sugo\",\n",
    "\"minestra\",\n",
    "\"pasta_bianco\",\n",
    "\"mele\",\n",
    "\"riso_bianco\",\n",
    "\"pere\",\n",
    "\"pasta_tonno_e_piselli\",\n",
    "\"medaglioni_di_carne\",\n",
    "\"pasta_ricotta_e_salsiccia\",\n",
    "\"piselli\",\n",
    "\"merluzzo_alle_olive\",\n",
    "\"finocchi_in_umido\",\n",
    "\"torta_ananas\",\n",
    "\"passato_alla_piemontese\",\n",
    "\"pasta_sugo_vegetariano\",\n",
    "\"pasta_tonno\",\n",
    "\"cibo_bianco_non_identificato\",\n",
    "\"guazzetto_di_calamari\",\n",
    "\"stinco_di_maiale\",\n",
    "\"strudel\",\n",
    "\"zucchine_impanate\",\n",
    "\"zucchine_umido\",\n",
    "\"roastbeef\",\n",
    "\"crema_zucca_e_fagioli\",\n",
    "\"lasagna_alla_bolognese\",\n",
    "\"finocchi_gratinati\",\n",
    "\"pasta_pancetta_e_zucchine\",\n",
    "\"rucola\",\n",
    "\"orecchiette_(ragu)\",\n",
    "\"arrosto_di_vitello\",\n",
    "\"pasta_e_ceci\",\n",
    "\"torta_crema\",\n",
    "\"torta_salata_(alla_valdostana)\",\n",
    "\"pasta_cozze_e_vongole\",\n",
    "\"banane\",\n",
    "\"pasta_pesto_besciamella_e_cornetti\",\n",
    "\"pasta_e_fagioli\",\n",
    "\"torta_salata_rustica_(zucchine)\",\n",
    "\"bruscitt\",\n",
    "\"focaccia_bianca\",\n",
    "\"pesce_2_(filetto)\",\n",
    "\"torta_crema_2\",\n",
    "\"pasta_sugo_pesce\",\n",
    "\"polpette_di_carne\",\n",
    "\"salmone_(da_menu_sembra_spada_in_realta)\",\n",
    "\"cavolfiore\",\n",
    "\"torta_salata_3\",\n",
    "\"minestra_lombarda\",\n",
    "\"patate/pure_prosciutto\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels-filtered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\"name\": labels.keys(), \"meals\": [labels for labels in labels.values()]}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder = \"datasets/UNIMIB2016/val/labels/\"\n",
    "files_to_filter_out = sorted(os.listdir(folder))\n",
    "\n",
    "\n",
    "def get_label_counts(dir, files):\n",
    "    data = get_labels(dir, files)\n",
    "    counts = {}\n",
    "    for values in data.values():\n",
    "        for v in values:\n",
    "            counts.setdefault(v, 0)\n",
    "            counts[v] += 1\n",
    "    return (\n",
    "        pd.DataFrame({\"name\": counts.keys(), \"counts\": counts.values()})\n",
    "        .sort_values(\"counts\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "\n",
    "get_label_counts(folder, files_to_filter_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def split_data_in_train_test_val():\n",
    "    images_dir = r\"datasets\\UNIMIB2016\\orig\\images\"\n",
    "    labels_dir = r\"datasets\\UNIMIB2016\\orig\\labels_segmentation\"\n",
    "\n",
    "    # Create the train, test, val directories if they don't exist\n",
    "    os.makedirs(\"datasets/UNIMIB2016/train/images\", exist_ok=True)\n",
    "    os.makedirs(\"datasets/UNIMIB2016/train/labels\", exist_ok=True)\n",
    "    os.makedirs(\"datasets/UNIMIB2016/test/images\", exist_ok=True)\n",
    "    os.makedirs(\"datasets/UNIMIB2016/test/labels\", exist_ok=True)\n",
    "    os.makedirs(\"datasets/UNIMIB2016/val/images\", exist_ok=True)\n",
    "    os.makedirs(\"datasets/UNIMIB2016/val/labels\", exist_ok=True)\n",
    "\n",
    "    # Get the list of image and label files\n",
    "    image_files = sorted(os.listdir(images_dir))\n",
    "    label_files = sorted(os.listdir(labels_dir))\n",
    "\n",
    "    # Shuffle the files\n",
    "    indices = np.arange(len(image_files))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Split the files\n",
    "    train_indices = indices[: int(0.7 * len(indices))]\n",
    "    val_indices = indices[int(0.7 * len(indices)) : int(0.85 * len(indices))]\n",
    "    test_indices = indices[int(0.85 * len(indices)) :]\n",
    "\n",
    "    for i in train_indices:\n",
    "        shutil.copy(\n",
    "            os.path.join(images_dir, image_files[i]), \"datasets/UNIMIB2016/train/images\"\n",
    "        )\n",
    "        shutil.copy(\n",
    "            os.path.join(labels_dir, label_files[i]), \"datasets/UNIMIB2016/train/labels\"\n",
    "        )\n",
    "\n",
    "    for i in val_indices:\n",
    "        shutil.copy(\n",
    "            os.path.join(images_dir, image_files[i]), \"datasets/UNIMIB2016/val/images\"\n",
    "        )\n",
    "        shutil.copy(\n",
    "            os.path.join(labels_dir, label_files[i]), \"datasets/UNIMIB2016/val/labels\"\n",
    "        )\n",
    "\n",
    "    for i in test_indices:\n",
    "        shutil.copy(\n",
    "            os.path.join(images_dir, image_files[i]), \"datasets/UNIMIB2016/test/images\"\n",
    "        )\n",
    "        shutil.copy(\n",
    "            os.path.join(labels_dir, label_files[i]), \"datasets/UNIMIB2016/test/labels\"\n",
    "        )\n",
    "\n",
    "\n",
    "# split_data_in_train_test_val()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Image module from PIL library\n",
    "def rotate_images_in_folder(folder):\n",
    "    # Loop through all the jpg files in the folder myimages\n",
    "    for file in tqdm(glob.glob(folder + \"/*.jpg\")):\n",
    "        # Open the image file\n",
    "        image = Image.open(file)\n",
    "        # Rotate the image by 180 degrees\n",
    "        image_rot = image.rotate(180)\n",
    "        # Save the rotated image with the same file name\n",
    "        image_rot.save(file)\n",
    "\n",
    "\n",
    "# rotate_images_in_folder(r\"C:\\Users\\malte.iwanicki\\Documents\\bachelor\\BachelorInformatikAbschlussarbeit\\src\\datasets\\UNIMIB2016\\orig\\images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_path=None):\n",
    "    if model_path:\n",
    "        return YOLO(model_path)\n",
    "    # return YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
    "    return YOLO(\"yolov8m-seg.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "\n",
    "model = (\n",
    "    get_model()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs, data):\n",
    "    model.train(\n",
    "        data=data, epochs=epochs, task=\"segment\", workers=8, batch=-1\n",
    "    )  # train the model\n",
    "\n",
    "\n",
    "train_model(model, epochs=100, data=\"config.yaml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    metrics = model.val()  # evaluate model performance on the validation set\n",
    "    return metrics\n",
    "\n",
    "evaluate_model(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(pt_file):\n",
    "    model = YOLO(pt_file)\n",
    "    return model\n",
    "\n",
    "model = load_model(r\"runs\\segment\\train10\\weights\\best.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image_file):\n",
    "    im1 = Image.open(image_file)\n",
    "    results = model.predict(source=im1, save=False)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the image file\n",
    "def get_plot(name):\n",
    "    img_file = rf\"datasets\\UNIMIB2016\\val\\images\\{name}.jpg\"\n",
    "    result = predict(model, img_file)\n",
    "    plt = Image.fromarray(result[0].plot())\n",
    "    plt.thumbnail((500, 400))\n",
    "    return plt\n",
    "\n",
    "\n",
    "# Get list of image and label files\n",
    "image_dir = r\"datasets\\UNIMIB2016\\val\\images\"\n",
    "image_files = sorted(os.listdir(image_dir))\n",
    "\n",
    "# Create widgets\n",
    "output = widgets.Output()\n",
    "dropdown = widgets.Dropdown(options=image_files)\n",
    "button_next = widgets.Button(description=\">\", layout=Layout(width=\"auto\"))\n",
    "button_prev = widgets.Button(description=\"<\", layout=Layout(width=\"auto\"))\n",
    "\n",
    "\n",
    "# Create function to update widgets\n",
    "def update_image(name):\n",
    "    # Clear the previous output\n",
    "    output.clear_output()\n",
    "\n",
    "    # Display the image with polygons\n",
    "    with output:\n",
    "        display(get_plot(os.path.splitext(name)[0]))\n",
    "\n",
    "\n",
    "def on_button_next_clicked(b):\n",
    "    dropdown.index = (dropdown.index + 1) % len(dropdown.options)\n",
    "\n",
    "\n",
    "def on_button_prev_clicked(b):\n",
    "    dropdown.index = (dropdown.index - 1) % len(dropdown.options)\n",
    "\n",
    "\n",
    "# Attach the update function to dropdown changes\n",
    "dropdown.observe(lambda change: update_image(change[\"new\"]), names=\"value\")\n",
    "button_next.on_click(lambda b: on_button_next_clicked(b))\n",
    "button_prev.on_click(lambda b: on_button_prev_clicked(b))\n",
    "\n",
    "# Display widgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(widgets.HBox([button_prev, dropdown, button_next]), output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
